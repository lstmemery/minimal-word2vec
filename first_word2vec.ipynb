{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize.api import StringTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'You will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings. I arrived here yesterday, and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_corpus = corpus.split(' ')\n",
    "vocabulary = list(set(split_corpus)) # Token should only appear once\n",
    "vocabulary_indices = list(range(len(vocabulary)))\n",
    "vocabulary_size = len(vocabulary_indices)\n",
    "word_to_index = dict(zip(vocabulary, vocabulary_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'dear': 1,\n",
       " 'here': 2,\n",
       " 'such': 3,\n",
       " 'no': 4,\n",
       " 'I': 5,\n",
       " 'first': 6,\n",
       " 'disaster': 7,\n",
       " 'in': 8,\n",
       " 'undertaking.': 9,\n",
       " 'welfare': 10,\n",
       " 'has': 11,\n",
       " 'hear': 12,\n",
       " 'which': 13,\n",
       " 'that': 14,\n",
       " 'my': 15,\n",
       " 'an': 16,\n",
       " 'task': 17,\n",
       " 'commencement': 18,\n",
       " 'arrived': 19,\n",
       " 'increasing': 20,\n",
       " 'you': 21,\n",
       " 'is': 22,\n",
       " 'confidence': 23,\n",
       " 'accompanied': 24,\n",
       " 'of': 25,\n",
       " 'have': 26,\n",
       " 'enterprise': 27,\n",
       " 'You': 28,\n",
       " 'to': 29,\n",
       " 'evil': 30,\n",
       " 'sister': 31,\n",
       " 'rejoice': 32,\n",
       " 'will': 33,\n",
       " 'assure': 34,\n",
       " 'with': 35,\n",
       " 'forebodings.': 36,\n",
       " 'yesterday,': 37,\n",
       " 'and': 38,\n",
       " 'regarded': 39,\n",
       " 'success': 40}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2\n",
    "corpus_size = len(split_corpus)\n",
    "\n",
    "\n",
    "index_pairs = []\n",
    "for position, word in enumerate(split_corpus):\n",
    "    window_minimum = max(position - WINDOW_SIZE, 0)\n",
    "    window_maximum = min(position + WINDOW_SIZE + 1, corpus_size)\n",
    "    for window_position in range(window_minimum, window_maximum):\n",
    "        if position != window_position:\n",
    "            index_pairs.append((word_to_index[split_corpus[window_position]], word_to_index[word]))\n",
    "\n",
    "index_pairs = np.array(index_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "NUMBER_OF_EPOCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(position):\n",
    "    one_hot_vector = torch.zeros(vocabulary_size).float()\n",
    "    one_hot_vector[position] = 1.0\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.03733890558544\n",
      "5.567180040008143\n",
      "5.220810454770138\n",
      "4.951218163339715\n",
      "4.734942854078192\n",
      "4.557548101324784\n",
      "4.409391243834245\n",
      "4.283826636013232\n",
      "4.176110553741455\n",
      "4.082727767291822\n",
      "4.000993476415935\n"
     ]
    }
   ],
   "source": [
    "InputEmbeddingLayer = Variable(torch.randn(EMBEDDING_DIMENSIONS, vocabulary_size).float(), requires_grad=True)\n",
    "OutputEmbeddingLayer = Variable(torch.randn(vocabulary_size, EMBEDDING_DIMENSIONS).float(), requires_grad=True)\n",
    "\n",
    "for epoch in range(NUMBER_OF_EPOCHES):\n",
    "    epoch_loss = 0\n",
    "    for context, target in index_pairs:\n",
    "        input_vector = Variable(one_hot_encoding(context)).float()\n",
    "        ground_truth = Variable(torch.from_numpy(np.array([target])).long())\n",
    "        \n",
    "        input_embedding = torch.matmul(InputEmbeddingLayer, input_vector)\n",
    "        output_embedding = torch.matmul(OutputEmbeddingLayer, input_embedding)\n",
    "        \n",
    "        log_softmax = F.log_softmax(output_embedding, dim=0)\n",
    "        loss = F.nll_loss(log_softmax.unsqueeze(0), ground_truth)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        InputEmbeddingLayer.data -= LEARNING_RATE * InputEmbeddingLayer.grad.data\n",
    "        OutputEmbeddingLayer.data -= LEARNING_RATE * OutputEmbeddingLayer.grad.data\n",
    "        \n",
    "        InputEmbeddingLayer.grad.data.zero_()\n",
    "        OutputEmbeddingLayer.grad.data.zero_()\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch_loss / len(index_pairs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
